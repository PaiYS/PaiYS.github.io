<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Yun Suen Pai</title> <meta name="author" content="Yun Suen Pai"/> <meta name="description" content="Human-Computer Interaction researcher exploring XR for assistance and augmentation. Lecturer at University of Auckland, New Zealand. "/> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"/> <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ü•ß</text></svg>"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="www.yunsuenpai.com/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> <title>about | Yun Suen Pai</title> <meta name="generator" content="Jekyll v4.3.4"/> <meta property="og:title" content="about"/> <meta property="og:locale" content="en"/> <meta name="description" content="Human-Computer Interaction researcher exploring XR for assistance and augmentation. Lecturer at University of Auckland, New Zealand."/> <meta property="og:description" content="Human-Computer Interaction researcher exploring XR for assistance and augmentation. Lecturer at University of Auckland, New Zealand."/> <link rel="canonical" href="www.yunsuenpai.com/"/> <meta property="og:url" content="www.yunsuenpai.com/"/> <meta property="og:site_name" content="Yun Suen Pai"/> <meta property="og:type" content="website"/> <meta name="twitter:card" content="summary"/> <meta property="twitter:title" content="about"/> <script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebSite","description":"Human-Computer Interaction researcher exploring XR for assistance and augmentation. Lecturer at University of Auckland, New Zealand.","headline":"about","name":"Yun Suen Pai","url":"www.yunsuenpai.com/"}</script> <script async src="https://www.googletagmanager.com/gtag/js?id=UA-148754131-1"></script> <script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-148754131-1");</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title"> Yun Suen Pai </h1> <p class="desc"><a href="https://profiles.auckland.ac.nz/yun-suen-pai/about" target="_blank" rel="noopener noreferrer">Lecturer</a>.</p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/pai_kmd-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/pai_kmd-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/pai_kmd-1400.webp"></source> <img src="/assets/img/pai_kmd.png" class="img-fluid z-depth-1 rounded-circle" width="auto" height="auto" alt="pai_kmd.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="address"> <p><a href="mailto:yun.suen.pai@auckland.ac.nz">yun.suen.pai@auckland.ac.nz</a></p> <p>School of Computer Science, University of Auckland, </p> <p>Auckland, New Zealand</p> </div> </div> <div class="clearfix"> <p>My vision of the future is that of an Inclusive Reality. It is a future where the sense of reality can be leveraged to bridge social and ability gaps towards an inclusive prosocial space. To achieve this, I explore systems that</p> <ul> <li>understand cognitive, behavioral and emotional states,</li> <li>assist the self and others, and</li> <li>augment abilities to empower diverse individuals.</li> </ul> <p>I graduated from the University of Malaya, Malaysia (UM) in 2013 with a degree in Computer-Aided Design and Manufacturing Engineering. I then furthered my research at UM which focuses on the use of AR technology for simulating machining processes, to obtain my Masters in Engineering Science in 2015. In 2018, I earned my Ph.D in Media Design from the Keio University Graduate School of Media Design (KMD) with my thesis entitled ‚ÄúConvex Interactions: Towards Efficient Human Motion in Peripersonal Space Using Virtual Reality‚Äù. For my postdoctoral research, I travelled to New Zealand to join the <a href="http://empathiccomputing.org/" target="_blank" rel="noopener noreferrer">Empathic Computing Laboratory</a> (ECL) for 2 years. Afterwards, I was a Project Senior Assistant Professor (non-tenured) at KMD, directing the <a href="https://www.embodiedmedia.org/teams/physionetic-interactions" target="_blank" rel="noopener noreferrer">Physionetic Interactions Group</a> in the <a href="https://www.embodiedmedia.org/about" target="_blank" rel="noopener noreferrer">Embodied Media Laboratory</a> until 2023. I am currently a <a href="https://profiles.auckland.ac.nz/yun-suen-pai/about" target="_blank" rel="noopener noreferrer">Lecturer</a> (tenured) in the University of Auckland, New Zealand where I co-direct ECL with Prof Mark Billinghurst.</p> <p>Besides research, I also love travelling, gaming, airsoft, customizing keyboards, collecting watches, and messing with my corgi, <a href="https://www.instagram.com/hci.with.bambi/?igshid=YmMyMTA2M2Y%3D" target="_blank" rel="noopener noreferrer">Bambi</a>. Hit me up anytime if you are into any of these things!</p> </div> <div class="news"> <h2>news</h2> <div class="table-responsive" style="max-height: 30vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row">Dec 4, 2024</th> <td> Siggraph Asia 2024 have started at the Tokyo International Forum! Come find me at the Experience Hall as I will be chairing the XR session. </td> </tr> <tr> <th scope="row">Sep 21, 2024</th> <td> <a href="https://scholar.google.com/citations?user=cPYLuiMAAAAJ&amp;hl=en" target="_blank" rel="noopener noreferrer">Danyang Peng</a> and <a href="https://scholar.google.com/citations?user=WwqSQWIAAAAJ&amp;hl=en" target="_blank" rel="noopener noreferrer">Shengyin Li</a>, PhD students from Keio University Graduate School of Media Design, will be visiting students at UoA! Danyang‚Äôs research is on multimodal mindfulness in XR and Shengyin is exploring the use of AI for self reflection. </td> </tr> <tr> <th scope="row">May 15, 2024</th> <td> <a href="https://scholar.google.com/citations?user=zfVf7wsAAAAJ&amp;hl=en" target="_blank" rel="noopener noreferrer">Weijen Chen</a> is presenting our CHI paper today! The work is about leveraging cymatics to change the perception of taste, read more about it <a href="https://dl.acm.org/doi/abs/10.1145/3613904.3642920" target="_blank" rel="noopener noreferrer">here</a>. </td> </tr> <tr> <th scope="row">May 2, 2024</th> <td> Thanks a lot to Mark Billinghurst and Gun Lee for inviting me as a speaker for the <a href="https://www.unisa.edu.au/research/ive/" target="_blank" rel="noopener noreferrer">UniSA IVE</a> Seminar Series! Full video of the talk can be found <a href="https://unisa.au.panopto.com/Panopto/Pages/Viewer.aspx?id=2ed81ec3-6514-4bfc-b9bb-b1650037248a" target="_blank" rel="noopener noreferrer">here</a>. </td> </tr> <tr> <th scope="row">Feb 3, 2024</th> <td> <a href="https://scholar.google.com/citations?user=ZNdiVuwAAAAJ&amp;hl=en" target="_blank" rel="noopener noreferrer">Yulan Ju</a>, PhD student from Keio University Graduate School of Media Design, will be a visiting student at UoA! Her research is on understanding the individual differences in affective haptic communication. </td> </tr> <tr> <th scope="row">Dec 3, 2023</th> <td> Starting my new position as a Lecturer at the School of Computer Science, University of Auckland today! If you‚Äôre nearby, come drop by at my office at 303-519 to say hi! </td> </tr> <tr> <th scope="row">Nov 24, 2023</th> <td> Will be travelling to Germany to attend the <a href="https://www.dagstuhl.de/23482" target="_blank" rel="noopener noreferrer">Dagstuhl Seminar on Social XR</a>. Looking forward to many thought-provoking discussions! </td> </tr> <tr> <th scope="row">Oct 26, 2023</th> <td> <a href="https://giulia-barbareschi.com/" target="_blank" rel="noopener noreferrer">Giulia Barbareschi</a> and I were recently interviewed by JST regarding our research in <a href="https://sj.jst.go.jp/interviewsandopinions/2023/c1027-01m.html" target="_blank" rel="noopener noreferrer">Moonshot program on increasing accessibility and understanding emotions</a>, do have a look! (Podcast link included) </td> </tr> <tr> <th scope="row">Oct 14, 2023</th> <td> Our previously published paper at IMWUT, Total VRecall, has been awarded the IMWUT Vol. 6 Distinguished Paper Award at Ubicomp/ISWC 2023! Only 8 out of 210 papers received the award, big congratulations especially to Kunal! You can read more about the paper <a href="https://yunsuenpai.com/assets/pdf/total_vrecall.pdf" target="_blank" rel="noopener noreferrer">here</a>. </td> </tr> <tr> <th scope="row">Jul 1, 2023</th> <td> My interview by Eva Wolfangel regarding the future of spatial computing is now out in the German version of MIT technology review! The article is available online <a href="https://www.heise.de/select/tr/2023/7/2320908254643308437" target="_blank" rel="noopener noreferrer">here</a>, yet it requires paid subscription. Luckily, since you‚Äôre here, <a href="https://yunsuenpai.com/assets/pdf/german_MIT_technology_interview.pdf" target="_blank" rel="noopener noreferrer">this</a> links to the PDF file directly ;) </td> </tr> <tr> <th scope="row">May 20, 2023</th> <td> My research topic is now <a href="https://www.frontiersin.org/research-topics/56138/xr-for-pro-social-behaviour-change-from-empathy-to-assistance?utm_source=F-RTM&amp;utm_medium=TED1&amp;utm_campaign=PRD_TED1_T1_RT-TITLE&amp;fbclid=IwAR17k4vK6fMtfAiqQFsbUwnC2z-gWIW9Co5lV161jAsh1CrEdXIU9MBSDQs" target="_blank" rel="noopener noreferrer">online on Frontiers</a>! Anyone doing research on XR for prosocial behaviour change, empathy and assistive XR, please feel free to submit your work here! The abstract submission deadline is 18 June, and the manuscript deadline is 16 October. </td> </tr> <tr> <th scope="row">Apr 12, 2023</th> <td> Thanks a lot to Mark and Alaeddin for inviting me as speaker at the Empathic Computing Lab. Full video of the talk can be found <a href="https://www.youtube.com/watch?v=l8jn0-RCxfQ" target="_blank" rel="noopener noreferrer">here</a>. Always good to be back! </td> </tr> <tr> <th scope="row">Mar 13, 2023</th> <td> Our paper got accepted for the CHI 2023 workshop - Towards an Inclusive and Accessible Metaverse. Papers are uploaded <a href="https://yunsuenpai.com/publications/" target="_blank" rel="noopener noreferrer">here</a> already! See you at CHI! </td> </tr> <tr> <th scope="row">Jan 15, 2023</th> <td> Our CHI paper on co-designing and evaluating AR dementia for medical workers got accepted! More details coming soon. </td> </tr> <tr> <th scope="row">Nov 1, 2022</th> <td> Thanks a lot to Shendong and Suranga for inviting me as <a href="https://events.comp.nus.edu.sg/view/19829" target="_blank" rel="noopener noreferrer">speaker at the NUS-HCI lab</a>. Full video of the talk can be found <a href="https://www.youtube.com/watch?v=IsupAfQPGcA" target="_blank" rel="noopener noreferrer">here</a>. Looking forward to future collaborations! </td> </tr> <tr> <th scope="row">Aug 18, 2022</th> <td> More works accepted! 2 papers to ISMAR, 1 to Siggraph Asia XR, 2 to UIST! Congrats to <a href="https://www.prasanthsasikumar.com/" target="_blank" rel="noopener noreferrer">Prasanth</a> and Anish for the ISMAR papers, Kinga for the Siggraph paper, and Shunyi and Zhang Qing for the UIST papers! </td> </tr> <tr> <th scope="row">Aug 15, 2022</th> <td> Working on XR or telexistence-related research and wish to visit Japan end of the year? Highly recommend to submit your work to <a href="https://icat.vrsj.org/2022/?fbclid=IwAR10n7vQRyaK0_KJPXtc4chYK387sevLKP1HhOjbHgwRZyea5tX2qy6NSc4" target="_blank" rel="noopener noreferrer">ICAT-EGVE!</a> The deadline for full paper submission has been extended to September 10. </td> </tr> <tr> <th scope="row">Aug 1, 2022</th> <td> The new website is finally updated and online! </td> </tr> <tr> <th scope="row">Jun 26, 2022</th> <td> Our UIST paper on smart glasses to simulate visual impairment got accepted! More details coming soon. </td> </tr> <tr> <th scope="row">Apr 24, 2022</th> <td> Our IMWUT paper on emotional autobiograhical memory in VR got accepted! Congrats to all the authors, especially Kunal. <img class="emoji" title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20"> </td> </tr> </table> </div> </div> <div class="publications"> <h2>selected publications</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/cymatics_main.png"></div> <div id="chen2024cymatics" class="col-sm-8"> <div class="title">Cymatics Cup: Shape-Changing Drinks by Leveraging Cymatics</div> <div class="author"> Chen, Weijen,¬†Yang, Yang,¬† Liu, Kao-Hua and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Pai, Yun Suen,¬†Yamaoka, Junichi,¬†Minamizawa, Kouta' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, 15); ">3 more authors</span> </div> <div class="periodical"> <em>In Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems</em> 2024 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://dl.acm.org/doi/abs/10.1145/3613904.3642920" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="/assets/pdf/cymatics.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>To enhance the dining experience, prior studies in Human-Computer Interaction (HCI) and gastrophysics have demonstrated that modifying the static shape of solid foods can amplify taste perception. However, the exploration of dynamic shape-changing mechanisms in liquid foods remains largely untapped. In the present study, we employ cymatics, a scientific discipline focused on utilizing sound frequencies to generate patterns in liquids and particles‚Äîto augment the drinking experience. Utilizing speakers, we dynamically reshaped liquids exhibiting five distinct taste profiles and evaluated resultant changes in taste perception and drinking experience. Our research objectives extend beyond merely augmenting taste from visual to tactile sensations; we also prioritize the experiential aspects of drinking. Through a series of experiments and workshops, we revealed a significant impact on taste perception and overall drinking experience when mediated by cymatics effects. Building upon these findings, we designed and developed tableware to integrate cymatics principles into gastronomic experiences.</p> </div> </div> </div> </li></ol> </div> <div class="social"> <div class="contact-icons"> <a href="https://scholar.google.com/citations?user=yzVKxRUAAAAJ" title="Google Scholar" target="_blank" rel="noopener noreferrer"><i class="ai ai-google-scholar"></i></a> <a href="https://orcid.org/0000-0002-6090-2837" title="ORCID" target="_blank" rel="noopener noreferrer"><i class="ai ai-orcid"></i></a> <a href="https://www.researchgate.net/profile/Yun-Suen-Pai-2/" title="ResearchGate" target="_blank" rel="noopener noreferrer"><i class="ai ai-researchgate"></i></a> <a href="https://dblp.org/pid/182/7081.html" title="DBLP" target="_blank" rel="noopener noreferrer"><i class="ai ai-dblp"></i></a> <a href="https://github.com/PaiYS" title="GitHub" target="_blank" rel="noopener noreferrer"><i class="fab fa-github"></i></a> <a href="https://www.linkedin.com/in/yun-suen-pai-96506a213" title="LinkedIn" target="_blank" rel="noopener noreferrer"><i class="fab fa-linkedin"></i></a> <a href="https://twitter.com/yun_suen_pai" title="Twitter" target="_blank" rel="noopener noreferrer"><i class="fab fa-twitter"></i></a> <a href="https://facebook.com/pai.ys.1" title="Facebook" target="_blank" rel="noopener noreferrer"><i class="fab fa-facebook"></i></a> </div> <div class="contact-note"> Best way to reach me is via email, and Google Scholar for the most updated publication list. </div> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> ¬© Copyright 2024 Yun Suen Pai. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. Last updated: December 26, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=UA-148754131-1"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-148754131-1");</script> </body> </html>